{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run preprocessed Data through a Model that predicts the identity: \n",
    "## See if we can make a more detailed analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers tqdm\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/content/preprocessed_df_1%_data.tsv'\n",
    "\n",
    "try:\n",
    "    toxicity_analysis_df = pd.read_csv(file_path, sep=\"\\t\")  \n",
    "except Exception as e:\n",
    "    print(f\"Error loading file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxicity_analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained model and tokenizer\n",
    "model_name = \"distilbert-base-uncased\"  # You can choose another model as well\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=8)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Define your identity labels\n",
    "identity_labels = [\n",
    "    \"male\",\n",
    "    \"female\",\n",
    "    \"homosexual_gay_or_lesbian\",\n",
    "    \"christian\",\n",
    "    \"jewish\",\n",
    "    \"muslim\",\n",
    "    \"black\",\n",
    "    \"white\",\n",
    "    \"psychiatric_or_mental_illness\"\n",
    "]\n",
    "\n",
    "# Function to predict identities for a batch of texts\n",
    "def predict_identities_batch(texts):\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    \n",
    "    # Move inputs to GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = {key: val.to('cuda') for key, val in inputs.items()}\n",
    "        model.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Apply sigmoid to get probabilities\n",
    "    probabilities = torch.sigmoid(logits).tolist()\n",
    "    return probabilities\n",
    "\n",
    "# Set the batch size\n",
    "batch_size = 32  # Adjust based on GPU memory\n",
    "\n",
    "# Initialize a list to store the results\n",
    "identity_results = []\n",
    "\n",
    "# Process the DataFrame in batches\n",
    "for i in tqdm(range(0, len(toxicity_analysis_df), batch_size), desc=\"Processing Identity Predictions\"):\n",
    "    batch_texts = toxicity_analysis_df['preprocessed'].iloc[i:i + batch_size].tolist()\n",
    "    batch_results = predict_identities_batch(batch_texts)\n",
    "    identity_results.extend(batch_results)\n",
    "\n",
    "results_df = pd.DataFrame(identity_results, columns=identity_labels)\n",
    "final_df = pd.concat([toxicity_analysis_df, results_df], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
